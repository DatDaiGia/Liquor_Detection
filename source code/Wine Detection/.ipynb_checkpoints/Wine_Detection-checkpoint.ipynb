{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "gxgtnJTayWrL",
    "outputId": "4ca92512-5bc8-48d8-edfe-576ff30ebcf4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WDFkBpGUHX23"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Lambda, Conv2D, MaxPool2D, BatchNormalization, ELU, Reshape, Concatenate, Activation\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from math import ceil, floor\n",
    "from data_generator import BatchGenerator\n",
    "from ssd_box_encode_decode_utils import SSDBoxEncoder, decode_y, decode_y2\n",
    "from keras_ssd_loss import SSDLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewgD4L_157_a"
   },
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EdY_iJEfynrk"
   },
   "outputs": [],
   "source": [
    "def create_model(img_size, \n",
    "                n_classes, \n",
    "                l2_regularization=None,\n",
    "                min_scale=0.1,\n",
    "                max_scale=0.9,\n",
    "                scales=None,\n",
    "                aspect_ratios_global=[0.5, 1.0, 2.0],\n",
    "                aspect_ratios_per_layer=None,\n",
    "                two_boxes_for_ar1=True,\n",
    "                steps=None,\n",
    "                offsets=None,\n",
    "                limit_boxes=True,\n",
    "                variances=[1.0, 1.0, 1.0, 1.0],\n",
    "                coords='centroids',\n",
    "                normalize_coords=False,\n",
    "                subtract_mean=None,\n",
    "                divide_by_stddev=None,\n",
    "                swap_channels=False,\n",
    "                return_predictor_sizes=False):\n",
    "    \n",
    "    n_predictor_layers = 4\n",
    "    n_classes += 1\n",
    "    \n",
    "    if len(variances) != 4: # We need one variance value for each of the four box coordinates\n",
    "        raise ValueError(\"4 variance values must be pased, but {} values were received.\".format(len(variances)))\n",
    "    variances = np.array(variances)\n",
    "    if np.any(variances <= 0):\n",
    "        raise ValueError(\"All variances must be > 0, but the variances given are {}\".format(variances))\n",
    "    \n",
    "    if (min_scale is None or max_scale is None) and scales is None:\n",
    "        raise ValueError(\"Either `min_scale` and `max_scale` or `scales` need to be specified.\")\n",
    "    \n",
    "    if scales:\n",
    "        if len(scales) != n_predictor_layers+1:\n",
    "            raise ValueError(\"It must be either scales is None or len(scales) == {}, but len(scales) == {}.\".format(n_predictor_layers+1, len(scales)))\n",
    "    else:\n",
    "        scales = np.linspace(min_scale, max_scale, n_predictor_layers+1)     \n",
    "\n",
    "    if aspect_ratios_global is None and aspect_ratios_per_layer is None:\n",
    "        raise ValueError(\"`aspect_ratios_global` and `aspect_ratios_per_layer` cannot both be None. At least one needs to be specified.\")\n",
    "    \n",
    "    if aspect_ratios_per_layer:\n",
    "        if len(aspect_ratios_per_layer) != n_predictor_layers:\n",
    "            raise ValueError(\"It must be either aspect_ratios_per_layer is None or len(aspect_ratios_per_layer) == {}, but len(aspect_ratios_per_layer) == {}.\".format(n_predictor_layers, len(aspect_ratios_per_layer)))\n",
    "            \n",
    "    if (not (steps is None)) and (len(steps) != n_predictor_layers):\n",
    "        raise ValueError(\"You must provide at least one step value per predictor layer.\")\n",
    "\n",
    "    if (not (offsets is None)) and (len(offsets) != n_predictor_layers):\n",
    "        raise ValueError(\"You must provide at least one offset value per predictor layer.\")\n",
    "        \n",
    "    if steps is None:\n",
    "        steps = [None] * n_predictor_layers\n",
    "    if offsets is None:\n",
    "        offsets = [None] * n_predictor_layers\n",
    "    \n",
    "    if aspect_ratios_per_layer:\n",
    "        n_boxes = []\n",
    "        for ar in aspect_ratios_per_layer:\n",
    "            if (1 in ar) & two_boxes_for_ar1:\n",
    "                n_boxes.append(len(ar) + 1)\n",
    "            else:\n",
    "                n_boxes.append(len(ar))\n",
    "    else:\n",
    "        if (1 in aspect_ratios_global) & two_boxes_for_ar1:\n",
    "            n_boxes = len(aspect_ratios_global) + 1\n",
    "        else:\n",
    "            n_boxes = len(aspect_ratios_global)\n",
    "        n_boxes = [n_boxes]*n_predictor_layers\n",
    "      \n",
    "    # Set the aspect ratio for each predictor layer, these only need for anchor boxes\n",
    "    if aspect_ratios_per_layer:\n",
    "        aspect_ratios = aspect_ratios_per_layer\n",
    "    else:\n",
    "        aspect_ratios = [aspect_ratios_global] * n_predictor_layers\n",
    "      \n",
    "    ## Building base model\n",
    "    l2_reg = l2_regularization\n",
    "    img_h, img_w, img_d = img_size[0], img_size[1], img_size[2]\n",
    "    x = Input(shape=(img_h, img_w, img_d))\n",
    "\n",
    "    x1 = Lambda(lambda z: z,\n",
    "                output_shape=(img_h, img_w, img_d),\n",
    "                name='identity_layer')(x)\n",
    "\n",
    "    if not (subtract_mean is None):\n",
    "        x1 = Lambda(lambda z: z - np.array(subtract_mean),\n",
    "                    output_shape=(img_h, img_w, img_d),\n",
    "                    name='input_mean_normalization')(x1)\n",
    "  \n",
    "    if not (divide_by_stddev is None):\n",
    "        x1 = Lambda(lambda z: z / np.array(divide_by_stddev),\n",
    "                    output_shape=(img_h, img_w, img_d),\n",
    "                    name='input_stddev_normalization')(x1)\n",
    "  \n",
    "    if swap_channels and img_size.shape[1] == 3:\n",
    "        x1 = Lambda(lambda z: z[:, ::-1],\n",
    "                    output_shape=(img_h, img_w, img_d),\n",
    "                    name='input_channel_swap')(x1)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv1')(x1)\n",
    "    conv1 = BatchNormalization(axis=3, momentum=0.99, name='bn1')(conv1)\n",
    "    conv1 = ELU(name='elu1')(conv1)\n",
    "    pool1 = MaxPool2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(48, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv2')(pool1)\n",
    "    conv2 = BatchNormalization(axis=3, momentum=0.99, name='bn2')(conv2)\n",
    "    conv2 = ELU(name='elu2')(conv2)\n",
    "    pool2 = MaxPool2D(pool_size=(2, 2), name='pool2')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(64, strides=(1, 1), kernel_size=(3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv3')(pool2)\n",
    "    conv3 = BatchNormalization(axis=3, name='bn3', momentum=0.99)(conv3)\n",
    "    conv3 = ELU(name='elu3')(conv3)\n",
    "    pool3 = MaxPool2D(pool_size=(2, 2), name='pool3')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv4')(pool3)\n",
    "    conv4 = BatchNormalization(axis=3, momentum=0.99, name='bn4')(conv4)\n",
    "    conv4 = ELU(name='elu4')(conv4)\n",
    "    pool4 = MaxPool2D(pool_size=(2, 2), name='pool4')(conv4)\n",
    "\n",
    "    conv5 = Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv5')(pool4)\n",
    "    conv5 = BatchNormalization(axis=3, momentum=0.99, name='bn5')(conv5)\n",
    "    conv5 = ELU(name='elu5')(conv5)\n",
    "    pool5 = MaxPool2D(pool_size=(2, 2), name='pool5')(conv5)\n",
    "\n",
    "    conv6 = Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv6')(pool5)\n",
    "    conv6 = BatchNormalization(axis=3, momentum=0.99, name='bn6')(conv6)\n",
    "    conv6 = ELU(name='elu6')(conv6)\n",
    "    pool6 = MaxPool2D(pool_size=(2, 2), name='pool6')(conv6)\n",
    "\n",
    "    conv7 = Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv7')(pool6)\n",
    "    conv7 = BatchNormalization(axis=3, momentum=0.99, name='bn7')(conv7)\n",
    "    conv7 = ELU(name='elu7')(conv7)\n",
    "\n",
    "    ## Build predictor layers\n",
    "    classes4 = Conv2D(n_boxes[0]*n_classes, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='class4')(conv4)\n",
    "    classes5 = Conv2D(n_boxes[1]*n_classes, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='class5')(conv5)\n",
    "    classes6 = Conv2D(n_boxes[2]*n_classes, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='class6')(conv6)\n",
    "    classes7 = Conv2D(n_boxes[3]*n_classes, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='class7')(conv7)\n",
    "\n",
    "    boxes4 = Conv2D(n_boxes[0]*4, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes4')(conv4)\n",
    "    boxes5 = Conv2D(n_boxes[1]*4, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes5')(conv5)\n",
    "    boxes6 = Conv2D(n_boxes[2]*4, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes6')(conv6)\n",
    "    boxes7 = Conv2D(n_boxes[3]*4, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes7')(conv7)\n",
    "\n",
    "    # Generate anchor-boxes\n",
    "    anchors4 = AnchorBoxes(img_h, img_w, this_scale=scales[0], next_scale=scales[1], aspect_ratios=aspect_ratios[0],\n",
    "                           two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[0], this_offsets=offsets[0],\n",
    "                           limit_boxes=limit_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords,\n",
    "                           name='anchors4')(boxes4)\n",
    "    anchors5 = AnchorBoxes(img_h, img_w, this_scale=scales[1], next_scale=scales[2], aspect_ratios=aspect_ratios[1],\n",
    "                           two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[1], this_offsets=offsets[1],\n",
    "                           limit_boxes=limit_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords,\n",
    "                           name='anchors5')(boxes5)\n",
    "    anchors6 = AnchorBoxes(img_h, img_w, this_scale=scales[2], next_scale=scales[3], aspect_ratios=aspect_ratios[2],\n",
    "                           two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[2], this_offsets=offsets[2],\n",
    "                           limit_boxes=limit_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords,\n",
    "                           name='anchors6')(boxes6)\n",
    "    anchors7 = AnchorBoxes(img_h, img_w, this_scale=scales[3], next_scale=scales[4], aspect_ratios=aspect_ratios[3],\n",
    "                           two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[3], this_offsets=offsets[3],\n",
    "                           limit_boxes=limit_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords,\n",
    "                           name='anchors7')(boxes7)\n",
    "    \n",
    "    # Reshape the class predictions, yielding 3D tensors of shape `(batch, height * width * n_boxes, n_classes)`\n",
    "    # We want the classes isolated in the last axis to perform softmax on them\n",
    "    classes4_reshaped = Reshape((-1, n_classes), name='class4_reshape')(classes4)\n",
    "    classes5_reshaped = Reshape((-1, n_classes), name='class5_reshape')(classes5)\n",
    "    classes6_reshaped = Reshape((-1, n_classes), name='class6_reshape')(classes6)\n",
    "    classes7_reshaped = Reshape((-1, n_classes), name='class7_reshape')(classes7)\n",
    "    \n",
    "    # Reshape the box coordinate predictions, yielding 3D tensors of shape `(batch, height * width * n_boxes, 4)`\n",
    "    # We want the four box coordinates isolated in the last axis to compute the smooth L1 loss\n",
    "    boxes4_reshaped = Reshape((-1, 4), name='boxes4_reshape')(boxes4)\n",
    "    boxes5_reshaped = Reshape((-1, 4), name='boxes5_reshape')(boxes5)\n",
    "    boxes6_reshaped = Reshape((-1, 4), name='boxes6_reshape')(boxes6)\n",
    "    boxes7_reshaped = Reshape((-1, 4), name='boxes7_reshape')(boxes7)\n",
    "    \n",
    "    # Reshape the anchor box tensors, yielding 3D tensors of shape `(batch, height * width * n_boxes, 8)`\n",
    "    anchors4_reshaped = Reshape((-1, 8), name='anchors4_reshape')(anchors4)\n",
    "    anchors5_reshaped = Reshape((-1, 8), name='anchors5_reshape')(anchors5)\n",
    "    anchors6_reshaped = Reshape((-1, 8), name='anchors6_reshape')(anchors6)\n",
    "    anchors7_reshaped = Reshape((-1, 8), name='anchors7_reshape')(anchors7)\n",
    "    \n",
    "    # Concatenate the predictions from the different layers and the assosciated anchor box tensors\n",
    "    # Axis 0 (batch) and axis 2 (n_classes or 4, respectively) are identical for all layer predictions,\n",
    "    # so we want to concatenate along axis 1\n",
    "    # Output shape of `classes_merged`: (batch, n_boxes_total, n_classes)\n",
    "    classes_concat = Concatenate(axis=1, name='classes_concat')([classes4_reshaped,\n",
    "                                                                 classes5_reshaped,\n",
    "                                                                 classes6_reshaped,\n",
    "                                                                 classes7_reshaped])\n",
    "\n",
    "    # Output shape of `boxes_final`: (batch, n_boxes_total, 4)\n",
    "    boxes_concat = Concatenate(axis=1, name='boxes_concat')([boxes4_reshaped,\n",
    "                                                             boxes5_reshaped,\n",
    "                                                             boxes6_reshaped,\n",
    "                                                             boxes7_reshaped])\n",
    "\n",
    "    # Output shape of `anchors_final`: (batch, n_boxes_total, 8)\n",
    "    anchors_concat = Concatenate(axis=1, name='anchors_concat')([anchors4_reshaped,\n",
    "                                                                 anchors5_reshaped,\n",
    "                                                                 anchors6_reshaped,\n",
    "                                                                 anchors7_reshaped])\n",
    "    \n",
    "    # The box coordinate predictions will go into the loss function just the way they are,\n",
    "    # but for the class predictions, we'll apply a softmax activation layer first\n",
    "    classes_softmax = Activation('softmax', name='classes_softmax')(classes_concat)\n",
    "    \n",
    "    # Concatenate the class and box coordinate predictions and the anchors to one large predictions tensor\n",
    "    # Output shape of `predictions`: (batch, n_boxes_total, n_classes + 4 + 8)\n",
    "    predictions = Concatenate(axis=2, name='predictions')([classes_softmax, boxes_concat, anchors_concat])\n",
    "    \n",
    "    model = Model(inputs=x, outputs=predictions)\n",
    "    \n",
    "    if return_predictor_sizes:\n",
    "        # Get the spatial dimensions (height, width) of the convolutional predictor layers, we need them to generate the default boxes\n",
    "        # The spatial dimensions are the same for the `classes` and `boxes` predictors\n",
    "        predictor_sizes = np.array([classes4._keras_shape[1:3],\n",
    "                                    classes5._keras_shape[1:3],\n",
    "                                    classes6._keras_shape[1:3],\n",
    "                                    classes7._keras_shape[1:3]])\n",
    "        return model, predictor_sizes\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0r_QCg750BY"
   },
   "source": [
    "## Setting params for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = '../../Liquor dataset'\n",
    "ANNOTATION_TRAIN_DIR = '../../Liquor dataset label/'\n",
    "ANNOTATION_TEST_DIR = '../../Liquor dataset label/Test/'\n",
    "IMG_H = 300\n",
    "IMG_W = 300\n",
    "IMG_D = 3\n",
    "SUBTRACT_MEAN = 127.5\n",
    "DIVIDE_BY_STDDEV = 127.5\n",
    "N_CLASSES = len(os.listdir(IMG_DIR))\n",
    "SCALES = [0.08, 0.16, 0.32, 0.64, 0.96]\n",
    "ASPECT_RATIO = [0.5, 1.0, 2.0]\n",
    "TWO_BOX_FOR_AR1 = True\n",
    "STEPS = None\n",
    "OFFSETS = None\n",
    "LIMIT_BOXES = False\n",
    "VARIANCES = [1.0, 1.0, 1.0, 1.0]\n",
    "COORDS = 'centroids'\n",
    "NORMALIZE_COORDS = False\n",
    "BATCH_SIZE = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/datnguyen/Documents/Git/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/datnguyen/Documents/Git/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/datnguyen/Documents/Git/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clear previous session\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/datnguyen/Documents/Git/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/datnguyen/Documents/Git/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/datnguyen/Documents/Git/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/datnguyen/Documents/Git/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = create_model(img_size=(IMG_H, IMG_W, IMG_D), \n",
    "                    n_classes=N_CLASSES + 1, \n",
    "                    l2_regularization=0.0,\n",
    "                    scales=SCALES,\n",
    "                    aspect_ratios_global=ASPECT_RATIO,\n",
    "                    aspect_ratios_per_layer=None,\n",
    "                    two_boxes_for_ar1=TWO_BOX_FOR_AR1,\n",
    "                    steps=STEPS,\n",
    "                    offsets=OFFSETS,\n",
    "                    limit_boxes=LIMIT_BOXES,\n",
    "                    variances=VARIANCES,\n",
    "                    coords='centroids',\n",
    "                    normalize_coords=NORMALIZE_COORDS,\n",
    "                    subtract_mean=SUBTRACT_MEAN,\n",
    "                    divide_by_stddev=DIVIDE_BY_STDDEV,\n",
    "                    swap_channels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 300, 300, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 300, 300, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 300, 300, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_stddev_normalization (Lam (None, 300, 300, 3)  0           input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 300, 300, 32) 896         input_stddev_normalization[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 300, 300, 32) 128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu1 (ELU)                      (None, 300, 300, 32) 0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 150, 150, 32) 0           elu1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 150, 150, 48) 13872       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 150, 150, 48) 192         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu2 (ELU)                      (None, 150, 150, 48) 0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 75, 75, 48)   0           elu2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 75, 75, 64)   27712       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 75, 75, 64)   256         conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu3 (ELU)                      (None, 75, 75, 64)   0           bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 37, 37, 64)   0           elu3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 37, 37, 64)   36928       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn4 (BatchNormalization)        (None, 37, 37, 64)   256         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu4 (ELU)                      (None, 37, 37, 64)   0           bn4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 18, 18, 64)   0           elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 18, 18, 48)   27696       pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn5 (BatchNormalization)        (None, 18, 18, 48)   192         conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu5 (ELU)                      (None, 18, 18, 48)   0           bn5[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 9, 9, 48)     0           elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 9, 9, 48)     20784       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn6 (BatchNormalization)        (None, 9, 9, 48)     192         conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu6 (ELU)                      (None, 9, 9, 48)     0           bn6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pool6 (MaxPooling2D)            (None, 4, 4, 48)     0           elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 4, 4, 32)     13856       pool6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn7 (BatchNormalization)        (None, 4, 4, 32)     128         conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "elu7 (ELU)                      (None, 4, 4, 32)     0           bn7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "class4 (Conv2D)                 (None, 35, 35, 36)   20772       elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "class5 (Conv2D)                 (None, 16, 16, 36)   15588       elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "class6 (Conv2D)                 (None, 7, 7, 36)     15588       elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "class7 (Conv2D)                 (None, 2, 2, 36)     10404       elu7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes4 (Conv2D)                 (None, 35, 35, 16)   9232        elu4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes5 (Conv2D)                 (None, 16, 16, 16)   6928        elu5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes6 (Conv2D)                 (None, 7, 7, 16)     6928        elu6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "boxes7 (Conv2D)                 (None, 2, 2, 16)     4624        elu7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "class4_reshape (Reshape)        (None, 4900, 9)      0           class4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "class5_reshape (Reshape)        (None, 1024, 9)      0           class5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "class6_reshape (Reshape)        (None, 196, 9)       0           class6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "class7_reshape (Reshape)        (None, 16, 9)        0           class7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors4 (AnchorBoxes)          (None, 35, 35, 4, 8) 0           boxes4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors5 (AnchorBoxes)          (None, 16, 16, 4, 8) 0           boxes5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors6 (AnchorBoxes)          (None, 7, 7, 4, 8)   0           boxes6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors7 (AnchorBoxes)          (None, 2, 2, 4, 8)   0           boxes7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "classes_concat (Concatenate)    (None, 6136, 9)      0           class4_reshape[0][0]             \n",
      "                                                                 class5_reshape[0][0]             \n",
      "                                                                 class6_reshape[0][0]             \n",
      "                                                                 class7_reshape[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "boxes4_reshape (Reshape)        (None, 4900, 4)      0           boxes4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes5_reshape (Reshape)        (None, 1024, 4)      0           boxes5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes6_reshape (Reshape)        (None, 196, 4)       0           boxes6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "boxes7_reshape (Reshape)        (None, 16, 4)        0           boxes7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "anchors4_reshape (Reshape)      (None, 4900, 8)      0           anchors4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors5_reshape (Reshape)      (None, 1024, 8)      0           anchors5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors6_reshape (Reshape)      (None, 196, 8)       0           anchors6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "anchors7_reshape (Reshape)      (None, 16, 8)        0           anchors7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classes_softmax (Activation)    (None, 6136, 9)      0           classes_concat[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "boxes_concat (Concatenate)      (None, 6136, 4)      0           boxes4_reshape[0][0]             \n",
      "                                                                 boxes5_reshape[0][0]             \n",
      "                                                                 boxes6_reshape[0][0]             \n",
      "                                                                 boxes7_reshape[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "anchors_concat (Concatenate)    (None, 6136, 8)      0           anchors4_reshape[0][0]           \n",
      "                                                                 anchors5_reshape[0][0]           \n",
      "                                                                 anchors6_reshape[0][0]           \n",
      "                                                                 anchors7_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 6136, 21)     0           classes_softmax[0][0]            \n",
      "                                                                 boxes_concat[0][0]               \n",
      "                                                                 anchors_concat[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 233,152\n",
      "Trainable params: 232,480\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_loss = SSDLoss(neg_pos_ratio=2, n_neg_min=0, alpha=1.0, beta = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=5e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/datnguyen/Documents/Git/env/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/datnguyen/Documents/Git/Asia Frontier Project/source code/Wine Detection/keras_ssd_loss.py:129: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/datnguyen/Documents/Git/Asia Frontier Project/source code/Wine Detection/keras_ssd_loss.py:76: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/datnguyen/Documents/Git/Asia Frontier Project/source code/Wine Detection/keras_ssd_loss.py:162: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'Chivas Regal',\n",
       " 'Jameson',\n",
       " 'Smirnoff',\n",
       " 'Remy Martin',\n",
       " 'Hennessy',\n",
       " 'Jack Daniel']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, LabelBinarizer\n",
    "\n",
    "os.listdir(IMG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_NAME = ['BackGround', 'Chivas Regal', 'Hennessy', 'Jack Daniel', 'Remy Martin', 'Smirnoff', 'Jameson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images():\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    list_dir = os.listdir(IMG_DIR)\n",
    "    \n",
    "    for ind, dr in enumerate(list_dir, start=1):\n",
    "        f_path = os.path.join(IMG_DIR, dr)\n",
    "        f_img_path = glob.glob(f_path + '/*.jpg')\n",
    "        if len(f_img_path) > 0:\n",
    "            image_paths.extend(f_img_path)\n",
    "        \n",
    "    image_paths = np.array(image_paths)\n",
    "    return image_paths.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths = get_all_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_image(image_paths):\n",
    "    labels = []\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        label = str(img_path.split('/')[-2])\n",
    "        labels.append(label)\n",
    "        \n",
    "    labels = np.array(labels)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels_images = get_labels_image(all_image_paths)\n",
    "all_labels_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(label):\n",
    "    for ind, item in enumerate(label):\n",
    "        if item == 'Chivas regal':\n",
    "            label[ind] = 'Chivas Regal'\n",
    "\n",
    "        if item == 'Jack daniels':\n",
    "            label[ind] = 'Jack Daniel'\n",
    "\n",
    "        if item == 'Remy martin':\n",
    "            label[ind] = 'Remy Martin'\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((183,), (183,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_image_paths, all_labels_images, test_size=0.2, \n",
    "                                                    random_state=42, shuffle=True)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder().fit(CLASSES_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = clean_data(y_train), clean_data(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = enc.transform(y_train), enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = to_categorical(y_train)\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# xml_list = glob.glob(ANNOTATION_DIR + '/*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handler = open(xml_list[0]).read()\n",
    "# soup = BeautifulSoup(handler)\n",
    "\n",
    "# soup.findAll('path')[0].text\n",
    "# soup.find('xmax').text\n",
    "\n",
    "# for message in soup.find('path'):\n",
    "#     print(message.text)\n",
    "# #     msg_attrs = dict(message.attrs)\n",
    "# #     f_user = message.find('from').user\n",
    "# #     f_user_dict = dict(f_user.attrs)\n",
    "# #     print \"%s: %s [%s @ %s]\" % (f_user_dict[u'friendlyname'],\n",
    "# #                                 message.find('text').decodeContents(),\n",
    "# #                                 msg_attrs[u'date'],\n",
    "# #                                 msg_attrs[u'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_sizes = [model.get_layer('class4').output_shape[1:3],\n",
    "                   model.get_layer('class5').output_shape[1:3],\n",
    "                   model.get_layer('class6').output_shape[1:3],\n",
    "                   model.get_layer('class7').output_shape[1:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_box_encoder = SSDBoxEncoder(img_height=IMG_H,\n",
    "                                img_width=IMG_W,\n",
    "                                n_classes=N_CLASSES, \n",
    "                                predictor_sizes=predictor_sizes,\n",
    "                                min_scale=None,\n",
    "                                max_scale=None,\n",
    "                                scales=SCALES,\n",
    "                                aspect_ratios_global=ASPECT_RATIO,\n",
    "                                aspect_ratios_per_layer=None,\n",
    "                                two_boxes_for_ar1=TWO_BOX_FOR_AR1,\n",
    "                                limit_boxes=LIMIT_BOXES,\n",
    "                                variances=VARIANCES,\n",
    "                                pos_iou_threshold=0.5,\n",
    "                                neg_iou_threshold=0.2,\n",
    "                                coords=COORDS,\n",
    "                                normalize_coords=NORMALIZE_COORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BatchGenerator(images_path=IMG_DIR, \n",
    "                               include_classes='all', \n",
    "                               box_output_format = ['class_id', 'xmin', 'xmax', 'ymin', 'ymax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datnguyen/Documents/Git/Asia Frontier Project/source code/Wine Detection/data_generator.py:639: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 639 of the file /Users/datnguyen/Documents/Git/Asia Frontier Project/source code/Wine Detection/data_generator.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(handler)\n"
     ]
    }
   ],
   "source": [
    "train_dataset.load_data_from_xml(annotations_path=ANNOTATION_TRAIN_DIR,\n",
    "                                 label_encoder=enc, \n",
    "                                 image_set_path=IMG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_dataset.generate(train=True,\n",
    "                                         ssd_box_encoder=ssd_box_encoder,\n",
    "                                         equalize=True,\n",
    "                                         brightness=(0.5,2,0.5),\n",
    "                                         flip=0.5,\n",
    "                                         translate=((0, 20), (0, 30), 0.5),\n",
    "                                         scale=(0.75, 1.2, 0.5),\n",
    "                                         crop=False,\n",
    "                                         random_crop=False,\n",
    "                                         resize=(IMG_H, IMG_W),\n",
    "                                         gray=False,\n",
    "                                         limit_boxes=True,\n",
    "                                         include_thresh=0.4,\n",
    "                                         diagnostics=False,\n",
    "                                         batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = BatchGenerator(include_classes='all',\n",
    "                              images_path=IMG_DIR,\n",
    "                              box_output_format=['class_id', 'xmin', 'xmax', 'ymin', 'ymax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.load_data_from_xml(annotations_path=ANNOTATION_TEST_DIR,\n",
    "                                label_encoder=enc,\n",
    "                                image_set_path=IMG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_dataset.generate(train=False,\n",
    "                                       ssd_box_encoder=ssd_box_encoder,\n",
    "                                       equalize=True,\n",
    "                                       brightness=(0.5,2,0.5),\n",
    "                                       flip=0.5,\n",
    "                                       translate=((0, 20), (0, 30), 0.5),\n",
    "                                       scale=(0.75, 1.2, 0.5),\n",
    "                                       crop=False,\n",
    "                                       random_crop=False,\n",
    "                                       resize=(IMG_H, IMG_W),\n",
    "                                       gray=False,\n",
    "                                       limit_boxes=True,\n",
    "                                       include_thresh=0.4,\n",
    "                                       diagnostics=False,\n",
    "                                       batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_dir = 'trained_model'\n",
    "\n",
    "if not os.path.exists(trained_dir):\n",
    "    os.mkdir(trained_dir)\n",
    "    \n",
    "file_path = os.path.join(trained_dir, 'model_checkpoint_epoch-{epoch:02d}_loss-{loss:.4d}_val_loss-{val_loss:.4d}.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath=file_path, \n",
    "                             monitor='val_loss',\n",
    "                             mode='auto',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint,\n",
    "#              learning_rate_scheduler,\n",
    "             early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.get_n_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [1,6136,7] vs. [1,6136,9]\n\t [[{{node training/Adam/gradients/loss/predictions_loss/mul_grad/BroadcastGradientArgs}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-39b0b76a91b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m",
      "\u001b[0;32m~/Documents/Git/env/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Git/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Git/env/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Git/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Git/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Git/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Git/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,6136,7] vs. [1,6136,9]\n\t [[{{node training/Adam/gradients/loss/predictions_loss/mul_grad/BroadcastGradientArgs}}]]"
     ]
    }
   ],
   "source": [
    "initial_epoch = 0\n",
    "number_epochs = 100\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, \n",
    "                              steps_per_epoch=floor(train_dataset.get_n_samples()/BATCH_SIZE), \n",
    "                              epochs=number_epochs,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=test_generator,\n",
    "                              validation_steps=floor(test_dataset.get_n_samples()/BATCH_SIZE),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Wine Detection",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
